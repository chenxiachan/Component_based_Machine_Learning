{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the open source code of paper: Utilizing Domain Knowledge: Robust Machine Learning for Building Energy Prediction with Small, Inconsistent Datasets.\n",
    "- @Date : 2022-06-24 16:21:35\n",
    "- @Link : https://arxiv.org/abs/2302.10784\n",
    "- @Ver : v02\n",
    "- @Author: Xia CHEN (xia.chen@iek.uni-hannover.de), Xia Chen, Manav Mahan Singh, Philipp Geyer\n",
    "---\n",
    "For using the code or data, please cite:\n",
    "\n",
    "*- Chen, X., Singh, M.M. and Geyer, P., 2023. Utilizing Domain Knowledge: Robust Machine Learning for Building Energy Prediction with Small, Inconsistent Datasets. arXiv preprint arXiv:2302.10784.*\n",
    "\n",
    "*- CHEN, Xia; Singh, Manav Mahan; Geyer, Philipp (2023), “Utilizing domain knowledge: robust machine learning for building energy performance prediction with small, inconsistent datasets”, Mendeley Data, V2, doi: 10.17632/fctghwx3r9.2*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "This code is designed to preprocess and transform building energy data for different components and zones for specific typical days, focusing on the winter period. The goal is to prepare the data for machine learning models, whether for training or testing purposes. Here’s a detailed breakdown of the script’s functionality:\n",
    "\n",
    "---\n",
    "1. **Define Time Period and Component Files**: It starts by specifying the analysis period (`'Winter Typical'`) and initializing the `COMPONENT` variable to the first file in a list of files. The script iterates over each file in this list, identifying the type of component (building, zone, etc.) based on the file name.\n",
    "---\n",
    "\n",
    "2. **Select Target Variables**: For each component type, it selects different target variables relevant to the analysis. For example, if the file pertains to typical days in a building, it focuses on the heating load. If it’s about zone typical\\ days, it considers various heat flows and the heating load as targets.\n",
    "---\n",
    "\n",
    "3. **Data Loading and Filtering**: The script differentiates between training and testing scenarios using the `TRAIN` boolean flag. It loads the appropriate dataset and, if a fast processing mode (`FAST`) is selected, samples a fraction of the data to expedite the analysis. This step is crucial for handling large datasets efficiently.\n",
    "---\n",
    "\n",
    "4. **Data Preparation**:\n",
    "    - **Column Renaming**: Columns prefixed with 'Building:' are renamed to 'Building_' to standardize column names.\n",
    "    - **Target Column Identification**: It identifies columns related to the specified period and prepares them for extraction and analysis.\n",
    "    - **Data Expansion**: For files with multiple values in a single cell (separated by semicolons), it expands these values into separate rows or columns, depending on the target variable. This is particularly important for the zone data, where heat flows are detailed.\n",
    "\n",
    "---\n",
    "\n",
    "5. **Output Dataframe Construction**: It constructs an output dataframe that:\n",
    "    - Excludes unwanted columns.\n",
    "    - Ensures the data is in a format suitable for machine learning models, converting string values to floats and rounding them for consistency.\n",
    "    - Joins weather data to the main dataframe, repeating weather entries to match the length of the main dataframe, ensuring each entry has corresponding weather information.\n",
    "---\n",
    "\n",
    "6. **Memory Optimization**: The script employs a function to reduce the memory usage of the dataframe, an essential step for handling large datasets efficiently.\n",
    "\n",
    "---\n",
    "7. **Saving the Transformed Data**: Finally, it saves the prepared dataframe to a CSV file, naming the file according to the component and the period analyzed. This naming convention facilitates easy identification of the dataset's contents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T09:06:37.683771Z",
     "start_time": "2023-07-12T09:06:34.655958Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.12.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys, gc, time, warnings, pickle, psutil, random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import csv\n",
    "from math import ceil\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import plotly.offline as py                    \n",
    "py.init_notebook_mode(connected=True)          \n",
    "import plotly.graph_objs as go                 \n",
    "import plotly.figure_factory as ff             \n",
    "\n",
    "# Target plot\n",
    "import seaborn as sns, matplotlib.pyplot as plt\n",
    "import random \n",
    "\n",
    "# For model training\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# pd.set_option('max_columns', 100)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "ROUTE = '../BoxTrainData/'\n",
    "ROUTE_test = '../RepTestData/'\n",
    "\n",
    "PERIOD = 'Winter Typical'\n",
    "TRAIN = True\n",
    "# Sample\n",
    "FAST = True\n",
    "# Traverse files\n",
    "g = os.walk(ROUTE)  \n",
    "\n",
    "files = []\n",
    "for path,dir_list,file_list in g:  \n",
    "    for file_name in file_list:  \n",
    "        files.append(file_name)\n",
    "files = files[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T09:06:37.695700Z",
     "start_time": "2023-07-12T09:06:37.684754Z"
    }
   },
   "outputs": [],
   "source": [
    "# :df pandas dataframe to reduce size             # type: pd.DataFrame()\n",
    "# :verbose                                        # type: bool\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                       df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T09:06:37.757558Z",
     "start_time": "2023-07-12T09:06:37.698716Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Dew</th>\n",
       "      <th>Hum</th>\n",
       "      <th>Pres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1986-01-01 01:00:00</th>\n",
       "      <td>1986</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-7.2</td>\n",
       "      <td>-8.4</td>\n",
       "      <td>90</td>\n",
       "      <td>95300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-01-01 02:00:00</th>\n",
       "      <td>1986</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-6.4</td>\n",
       "      <td>-7.6</td>\n",
       "      <td>90</td>\n",
       "      <td>94900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-01-01 03:00:00</th>\n",
       "      <td>1986</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-5.9</td>\n",
       "      <td>-7.1</td>\n",
       "      <td>90</td>\n",
       "      <td>94600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-01-01 04:00:00</th>\n",
       "      <td>1986</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>-6.8</td>\n",
       "      <td>90</td>\n",
       "      <td>94500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-01-01 05:00:00</th>\n",
       "      <td>1986</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>-6.6</td>\n",
       "      <td>91</td>\n",
       "      <td>94500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984-12-31 20:00:00</th>\n",
       "      <td>1984</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>20</td>\n",
       "      <td>-10.6</td>\n",
       "      <td>-11.1</td>\n",
       "      <td>96</td>\n",
       "      <td>96900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984-12-31 21:00:00</th>\n",
       "      <td>1984</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>21</td>\n",
       "      <td>-10.4</td>\n",
       "      <td>-10.9</td>\n",
       "      <td>95</td>\n",
       "      <td>96800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984-12-31 22:00:00</th>\n",
       "      <td>1984</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>-9.9</td>\n",
       "      <td>-10.6</td>\n",
       "      <td>94</td>\n",
       "      <td>96600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984-12-31 23:00:00</th>\n",
       "      <td>1984</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>-9.1</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>92</td>\n",
       "      <td>96200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985-01-01 00:00:00</th>\n",
       "      <td>1984</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>24</td>\n",
       "      <td>-8.2</td>\n",
       "      <td>-9.2</td>\n",
       "      <td>91</td>\n",
       "      <td>95800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8760 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Year  Month  Day  Hour  Temp   Dew  Hum   Pres\n",
       "1986-01-01 01:00:00  1986      1    1     1  -7.2  -8.4   90  95300\n",
       "1986-01-01 02:00:00  1986      1    1     2  -6.4  -7.6   90  94900\n",
       "1986-01-01 03:00:00  1986      1    1     3  -5.9  -7.1   90  94600\n",
       "1986-01-01 04:00:00  1986      1    1     4  -5.6  -6.8   90  94500\n",
       "1986-01-01 05:00:00  1986      1    1     5  -5.5  -6.6   91  94500\n",
       "...                   ...    ...  ...   ...   ...   ...  ...    ...\n",
       "1984-12-31 20:00:00  1984     12   31    20 -10.6 -11.1   96  96900\n",
       "1984-12-31 21:00:00  1984     12   31    21 -10.4 -10.9   95  96800\n",
       "1984-12-31 22:00:00  1984     12   31    22  -9.9 -10.6   94  96600\n",
       "1984-12-31 23:00:00  1984     12   31    23  -9.1 -10.0   92  96200\n",
       "1985-01-01 00:00:00  1984     12   31    24  -8.2  -9.2   91  95800\n",
       "\n",
       "[8760 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge with weather data\n",
    "\n",
    "weather_df = pd.read_csv('../Weather_data.csv')\n",
    "# to date_time and set as index\n",
    "date_df = weather_df[['Year', 'Month', 'Day', 'Hour']]\n",
    "date = pd.to_datetime(date_df)\n",
    "\n",
    "weather_df.index = date\n",
    "\n",
    "del date_df, date\n",
    "\n",
    "weather_df = weather_df[['Year', 'Month', 'Day', 'Hour','Temp','Dew','Hum','Pres']]\n",
    "weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T09:06:37.780480Z",
     "start_time": "2023-07-12T09:06:37.759529Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Dew</th>\n",
       "      <th>Hum</th>\n",
       "      <th>Pres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1986-01-05 01:00:00</th>\n",
       "      <td>1986</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.4</td>\n",
       "      <td>-7.7</td>\n",
       "      <td>82</td>\n",
       "      <td>95700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-01-05 02:00:00</th>\n",
       "      <td>1986</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>-6.9</td>\n",
       "      <td>-8.4</td>\n",
       "      <td>88</td>\n",
       "      <td>95700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-01-05 03:00:00</th>\n",
       "      <td>1986</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>-6.6</td>\n",
       "      <td>-7.9</td>\n",
       "      <td>89</td>\n",
       "      <td>95700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-01-05 04:00:00</th>\n",
       "      <td>1986</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>-8.2</td>\n",
       "      <td>-10.7</td>\n",
       "      <td>80</td>\n",
       "      <td>95600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-01-05 05:00:00</th>\n",
       "      <td>1986</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>-7.9</td>\n",
       "      <td>-10.2</td>\n",
       "      <td>82</td>\n",
       "      <td>95600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-01-17 20:00:00</th>\n",
       "      <td>1986</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>-2.7</td>\n",
       "      <td>95</td>\n",
       "      <td>96300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-01-17 21:00:00</th>\n",
       "      <td>1986</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>92</td>\n",
       "      <td>96400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-01-17 22:00:00</th>\n",
       "      <td>1986</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>93</td>\n",
       "      <td>96500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-01-17 23:00:00</th>\n",
       "      <td>1986</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>-4.9</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>95</td>\n",
       "      <td>96600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986-01-18 00:00:00</th>\n",
       "      <td>1986</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>24</td>\n",
       "      <td>-4.4</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>95</td>\n",
       "      <td>96600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>312 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Year  Month  Day  Hour  Temp   Dew  Hum   Pres\n",
       "1986-01-05 01:00:00  1986      1    5     1  -5.4  -7.7   82  95700\n",
       "1986-01-05 02:00:00  1986      1    5     2  -6.9  -8.4   88  95700\n",
       "1986-01-05 03:00:00  1986      1    5     3  -6.6  -7.9   89  95700\n",
       "1986-01-05 04:00:00  1986      1    5     4  -8.2 -10.7   80  95600\n",
       "1986-01-05 05:00:00  1986      1    5     5  -7.9 -10.2   82  95600\n",
       "...                   ...    ...  ...   ...   ...   ...  ...    ...\n",
       "1986-01-17 20:00:00  1986      1   17    20  -2.1  -2.7   95  96300\n",
       "1986-01-17 21:00:00  1986      1   17    21  -1.9  -2.9   92  96400\n",
       "1986-01-17 22:00:00  1986      1   17    22  -4.2  -5.0   93  96500\n",
       "1986-01-17 23:00:00  1986      1   17    23  -4.9  -5.5   95  96600\n",
       "1986-01-18 00:00:00  1986      1   17    24  -4.4  -5.0   95  96600\n",
       "\n",
       "[312 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the corresponding weather date\n",
    "if(PERIOD == 'Winter Typical'):\n",
    "    # 1/5-1/17\n",
    "    target_weather = weather_df.loc[(weather_df['Month'] == 1)&(weather_df['Day'] >= 5)&(weather_df['Day'] <= 17)]\n",
    "if(PERIOD == 'Winter Extreme'):\n",
    "    # 2/9-2/21\n",
    "    target_weather = weather_df.loc[(weather_df['Month'] == 2)&(weather_df['Day'] >= 9)&(weather_df['Day'] <= 21)]\n",
    "if(PERIOD == 'Spring'):\n",
    "    # 3/28-4/10\n",
    "    target_weather = weather_df.loc[(weather_df['Month'] == 2)&(weather_df['Day'] >= 9)&(weather_df['Day'] <= 21)]\n",
    "if(PERIOD == 'Summer Typical'):\n",
    "    # 7/12 - 7/24\n",
    "    target_weather = weather_df.loc[(weather_df['Month'] == 7)&(weather_df['Day'] >= 12)&(weather_df['Day'] <= 24)]\n",
    "if(PERIOD == 'Summer Extreme'):\n",
    "    # 7/19-7/31\n",
    "    target_weather = weather_df.loc[(weather_df['Month'] == 7)&(weather_df['Day'] >= 19)&(weather_df['Day'] <= 31)]\n",
    "if(PERIOD == 'Autumn'):\n",
    "    # 10/19-10/31\n",
    "    target_weather = weather_df.loc[(weather_df['Month'] == 10)&(weather_df['Day'] >= 19)&(weather_df['Day'] <= 31)]\n",
    "target_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T09:07:15.987912Z",
     "start_time": "2023-07-12T09:06:37.783465Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data\n",
      "369    Shape1_2291\n",
      "Name: File, dtype: object\n",
      "--------------------------------------------------\n",
      "BuildingTypicalDays.csv\n",
      "Winter Typical:Heating Load\n",
      "(1, 35)\n",
      "Not expand\n",
      "Winter Typical:Heating Load\n",
      "(312,)\n",
      "Mem. usage decreased to  0.03 Mb (74.1% reduction)\n",
      "*************************\n",
      "(312, 44)\n",
      "BuildingTypicalDays_Winter Typical.csv\n",
      "Training Data\n",
      "--------------------------------------------------\n",
      "GFloorTypicalDays.csv\n",
      "Winter Typical:Heat Flow\n",
      "(1, 6)\n",
      "Not expand\n",
      "Winter Typical:Heat Flow\n",
      "(312,)\n",
      "Mem. usage decreased to  0.01 Mb (59.8% reduction)\n",
      "*************************\n",
      "(312, 15)\n",
      "GFloorTypicalDays_Winter Typical.csv\n",
      "Training Data\n",
      "--------------------------------------------------\n",
      "InfiltrationTypicalDays.csv\n",
      "Winter Typical:Heat Flow\n",
      "(3, 12)\n",
      "Not expand\n",
      "Winter Typical:Heat Flow\n",
      "(936,)\n",
      "Mem. usage decreased to  0.05 Mb (64.2% reduction)\n",
      "*************************\n",
      "(936, 21)\n",
      "InfiltrationTypicalDays_Winter Typical.csv\n",
      "Training Data\n",
      "--------------------------------------------------\n",
      "RoofTypicalDays.csv\n",
      "Winter Typical:Heat Flow\n",
      "(1, 6)\n",
      "Not expand\n",
      "Winter Typical:Heat Flow\n",
      "(312,)\n",
      "Mem. usage decreased to  0.01 Mb (59.8% reduction)\n",
      "*************************\n",
      "(312, 15)\n",
      "RoofTypicalDays_Winter Typical.csv\n",
      "Training Data\n",
      "--------------------------------------------------\n",
      "WallWindowTypicalDays.csv\n",
      "Winter Typical:Heat Flow\n",
      "(12, 9)\n",
      "Not expand\n",
      "Winter Typical:Heat Flow\n",
      "(3744,)\n",
      "Mem. usage decreased to  0.19 Mb (63.9% reduction)\n",
      "*************************\n",
      "(3744, 18)\n",
      "WallWindowTypicalDays_Winter Typical.csv\n",
      "Training Data\n",
      "--------------------------------------------------\n",
      "ZoneTypicalDays.csv\n",
      "['Winter Typical:WallWindow Heat Flow', 'Winter Typical:GFloor Heat Flow', 'Winter Typical:Roof Heat Flow', 'Winter Typical:Infiltration Heat Flow', 'Winter Typical:Heating Load']\n",
      "(3, 36)\n",
      "Winter Typical:WallWindow Heat Flow\n",
      "(936,)\n",
      "Winter Typical:GFloor Heat Flow\n",
      "GFloor\n",
      "(936,)\n",
      "1285     2514.329\n",
      "1285     2383.238\n",
      "1285     2165.898\n",
      "1285     1961.945\n",
      "1285     1766.577\n",
      "Name: Winter Typical:GFloor Heat Flow, dtype: object\n",
      "Winter Typical:Roof Heat Flow\n",
      "Roof\n",
      "(936,)\n",
      "1287     -89.498\n",
      "1287      18.542\n",
      "1287       88.47\n",
      "1287     146.374\n",
      "1287     185.345\n",
      "Name: Winter Typical:Roof Heat Flow, dtype: object\n",
      "Winter Typical:Infiltration Heat Flow\n",
      "(936,)\n",
      "1285     -0.9000876\n",
      "1285     -0.9810161\n",
      "1285      -1.005464\n",
      "1285      -1.049422\n",
      "1285      -1.047936\n",
      "Name: Winter Typical:Infiltration Heat Flow, dtype: object\n",
      "Winter Typical:Heating Load\n",
      "(936,)\n",
      "1285       379.77\n",
      "1285     1668.699\n",
      "1285     2522.577\n",
      "1285     3255.202\n",
      "1285     3703.563\n",
      "Name: Winter Typical:Heating Load, dtype: object\n",
      "Mem. usage decreased to  0.09 Mb (73.7% reduction)\n",
      "*************************\n",
      "(936, 49)\n",
      "ZoneTypicalDays_Winter Typical.csv\n"
     ]
    }
   ],
   "source": [
    "# PERIOD = 'Winter Typical'\n",
    "\n",
    "# for\n",
    "# building, wall, zone...\n",
    "COMPONENT = files[0]\n",
    "for COMPONENT in files:\n",
    "    if(COMPONENT == 'BuildingTypicalDays.csv'):\n",
    "        TARGET = PERIOD+':Heating Load'\n",
    "    elif(COMPONENT == 'ZoneTypicalDays.csv'):\n",
    "        TARGET = [PERIOD+':WallWindow Heat Flow',\n",
    "                 PERIOD+':GFloor Heat Flow',\n",
    "                 PERIOD+':Roof Heat Flow',\n",
    "                 PERIOD+':Infiltration Heat Flow',\n",
    "                 PERIOD+':Heating Load']\n",
    "    else:\n",
    "        TARGET = PERIOD+':Heat Flow'\n",
    "    if(TRAIN == True):\n",
    "        # 读文件\n",
    "        target_df = pd.read_csv(ROUTE+COMPONENT)\n",
    "        print('Training Data')\n",
    "        if(FAST is True):\n",
    "            if(COMPONENT == 'BuildingTypicalDays.csv'):\n",
    "                #### SAMPLE!\n",
    "                TARGET_BUILDING = target_df['File'].sample(frac=0.000125)\n",
    "#                 TARGET_BUILDING = target_df['File'][:1000]\n",
    "                target_df = target_df[target_df['File'].isin(TARGET_BUILDING.values.tolist())]\n",
    "                print(TARGET_BUILDING)\n",
    "            else:\n",
    "                target_df = target_df[target_df['File'].isin(TARGET_BUILDING.values.tolist())]\n",
    "        elif(FAST is False):\n",
    "            TARGET_BUILDING = target_df['File']\n",
    "            target_df = target_df[target_df['File'].isin(TARGET_BUILDING.values.tolist())]\n",
    "    else:\n",
    "        target_df = pd.read_csv(ROUTE_test+COMPONENT)\n",
    "        print('Testing Data')\n",
    "        if(FAST is True):\n",
    "            if(COMPONENT == 'BuildingTypicalDays.csv'):\n",
    "            \n",
    "#                 TARGET_BUILDING = target_df['File'][:300]\n",
    "                TARGET_BUILDING = target_df['File']\n",
    "                target_df = target_df[target_df['File'].isin(TARGET_BUILDING.values.tolist())]\n",
    "                print(TARGET_BUILDING)\n",
    "            else:\n",
    "                target_df = target_df[target_df['File'].isin(TARGET_BUILDING.values.tolist())]\n",
    "        elif(FAST is False):\n",
    "            TARGET_BUILDING = target_df['File']\n",
    "            target_df = target_df[target_df['File'].isin(TARGET_BUILDING.values.tolist())]\n",
    "            \n",
    "    target_df.columns = target_df.columns.str.replace('Building:', 'Building_') \n",
    "\n",
    "    melt_target = [x for x in target_df.columns if PERIOD in x]\n",
    "    out_target = [x for x in target_df.columns if ':' in x]\n",
    "\n",
    "    retD = list(set(target_df.columns) - set(out_target))\n",
    "    retD.sort(key=list(target_df.columns).index)\n",
    "\n",
    "    output_df = target_df[retD]\n",
    "    print('-'*50)\n",
    "    print(COMPONENT)\n",
    "    print(TARGET)\n",
    "    print(output_df.shape)\n",
    "\n",
    "    num_dict = pd.DataFrame(target_df['File'].value_counts())\n",
    "    # num_dict['name'] = num_dict.index\n",
    "    num_dict = num_dict.loc[target_df['File'].drop_duplicates().tolist()]\n",
    "    num_dict\n",
    "    \n",
    "    if(COMPONENT == 'ZoneTypicalDays.csv'):\n",
    "        for each_target_column in TARGET:\n",
    "            print(each_target_column)\n",
    "\n",
    "            indicator = each_target_column.replace(PERIOD,'')\n",
    "            indicator = indicator.replace(':','')\n",
    "            indicator = indicator.replace(' Heat Flow','')\n",
    "\n",
    "            if(indicator == 'GFloor' or indicator == 'Roof'):\n",
    "                print(indicator)\n",
    "                test_df = target_df[['File', each_target_column]].dropna()\n",
    "\n",
    "                # New Dataframe\n",
    "                new_df = pd.DataFrame()\n",
    "                for a,b in zip(num_dict.index.tolist(), num_dict['File']):\n",
    "    #                 print(a,b)\n",
    "                    for i in range(0,b):\n",
    "                        new_df = pd.concat([new_df,test_df[test_df['File'] == a]],axis=0)\n",
    "                expand_df = new_df[each_target_column].str.split(';',expand=True).stack()\n",
    "                expand_df = expand_df.reset_index(level=1,drop=True).rename(each_target_column)\n",
    "                print(expand_df.shape)\n",
    "            else:\n",
    "                expand_df = target_df[each_target_column].str.split(';',expand=True).stack()\n",
    "                expand_df = expand_df.reset_index(level=1,drop=True).rename(each_target_column)\n",
    "                print(expand_df.shape)\n",
    "\n",
    "            if(each_target_column == TARGET[0]):\n",
    "                output_df = output_df.join(expand_df)\n",
    "            else:\n",
    "                print(expand_df.head())\n",
    "                output_df[each_target_column] = expand_df.values\n",
    "            output_df[each_target_column] = output_df[each_target_column].astype(float)\n",
    "            output_df = output_df.round(3)\n",
    "\n",
    "    else:\n",
    "        print('Not expand')\n",
    "        for each_target_column in [TARGET]:\n",
    "            print(each_target_column)\n",
    "            expand_df = target_df[each_target_column].str.split(';',expand=True).stack()\n",
    "            expand_df = expand_df.reset_index(level=1,drop=True).rename(each_target_column)\n",
    "            print(expand_df.shape)\n",
    "\n",
    "            output_df = output_df.join(expand_df)\n",
    "            output_df[each_target_column] = output_df[each_target_column].astype(float)\n",
    "            output_df = output_df.round(3)\n",
    "\n",
    "    # merge target_weather\n",
    "    target_weather = target_weather.reset_index(drop=True)\n",
    "    repeat_time = int(len(output_df)/len(target_weather))\n",
    "\n",
    "    merge_weather = pd.concat([target_weather]*repeat_time, ignore_index=True)\n",
    "    output_df = output_df.reset_index(drop=True)\n",
    "    output_df = pd.concat([merge_weather, output_df], axis=1)\n",
    "    \n",
    "    output_df = reduce_mem_usage(output_df)\n",
    "    print('*'*25)\n",
    "    print(output_df.shape)\n",
    "    \n",
    "    output_name =COMPONENT[:-4] + '_'+ PERIOD + '.csv'\n",
    "    print(output_name)\n",
    "    # file name: component + outputTARGET\n",
    "    output_name = output_name.replace(':',' ')\n",
    "    output_df.to_csv(output_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
